{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset for training\n",
    "- 1] Extract Frames from video\n",
    "- 2] Label convertion (COCOformats - YOLO - VOC)\n",
    "- 3] Display labels on images - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_directory(path_to):\n",
    "        \"\"\"Check if the saving directory exist, create it if not\"\"\"\n",
    "        if not os.path.isdir(path_to):\n",
    "            os.makedirs(path_to)\n",
    "\n",
    "        if path_to.endswith('/'):\n",
    "            return(path_to)\n",
    "        else:\n",
    "            return(path_to + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data\n",
    "path_to_video_folder = '../data/train_videos/'\n",
    "output_path = '../data/train_images/'\n",
    "output_path = check_directory(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 video to be processed.\n"
     ]
    }
   ],
   "source": [
    "# List of videos\n",
    "list_of_videos = os.listdir(path_to_video_folder)\n",
    "print(\"{} video to be processed.\".format(len(list_of_videos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to extract all the frame\n",
    "for vid in list_of_videos:\n",
    "    vid_name = vid.split('.')[0]\n",
    "    vid_path = path_to_video_folder + vid\n",
    "    vid_output_path = output_path + vid_name\n",
    "    print(\"Processing video {} ...\".format(vid_name))\n",
    "    \n",
    "    # Create sub-folder (maybe not needed?)\n",
    "    vid_output_path = check_directory(vid_output_path)\n",
    "    \n",
    "    # Extract frames\n",
    "    vid_cap = cv2.VideoCapture(vid_path)\n",
    "    \n",
    "    success, frame = vid_cap.read()\n",
    "    frame_id = 0\n",
    "    while success:\n",
    "      cv2.imwrite(vid_output_path + str(frame_id) + '.png', frame)\n",
    "      success, frame = vid_cap.read()\n",
    "      frame_id += 1\n",
    "    print(\"... extracted {} frames.\".format(frame_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label generation\n",
    "- coco: \"bbox\" : [x,y,width,height]\n",
    "- yolo: \"bbox\" : [x, y,width,height] normalize over image size\n",
    "\n",
    "COCO links:\n",
    "\n",
    "- [coco_lib](https://github.com/waspinator/pycococreator/blob/master/pycococreatortools/pycococreatortools.py)\n",
    "- [generator_example 1](https://github.com/waspinator/pycococreator/blob/master/examples/shapes/shapes_to_coco.py)\n",
    "- [format explained](https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch/#coco-dataset-format)\n",
    "- [generator example 2](https://patrickwasp.com/create-your-own-coco-style-dataset/)\n",
    "- [simple visualisation](https://github.com/waspinator/pycococreator/blob/master/examples/shapes/visualize_coco.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO dataset global\n",
    "INFO = {\n",
    "    \"description\": \"AI on edge dataset\",\n",
    "    \"url\": \"https://signate.jp/competitions/256/data\",\n",
    "    \"version\": \"0.1\",\n",
    "    \"year\": 2020,\n",
    "    \"contributor\": \"MLT\",\n",
    "    \"date_created\": \"2020/05\"\n",
    "}\n",
    "\n",
    "LICENSES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
    "        \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
    "    }\n",
    "]\n",
    "\n",
    "CATEGORIES = [\n",
    "    {\n",
    "        'id': 1,\n",
    "        'name': 'Car',\n",
    "        'supercategory': 'on_road',\n",
    "    },\n",
    "    {\n",
    "        'id': 2,\n",
    "        'name': 'Pedestrian',\n",
    "        'supercategory': 'on_street',\n",
    "    },\n",
    "    {\n",
    "        'id': 3,\n",
    "        'name': 'Truck',\n",
    "        'supercategory': 'on_road',\n",
    "    },\n",
    "    {\n",
    "        'id': 4,\n",
    "        'name': 'Signal',\n",
    "        'supercategory': 'on_road',\n",
    "    },\n",
    "    {\n",
    "        'id': 5,\n",
    "        'name': 'Signs',\n",
    "        'supercategory': 'on_road',\n",
    "    },\n",
    "    {\n",
    "        'id': 6,\n",
    "        'name': 'Bicycle',\n",
    "        'supercategory': 'on_road',\n",
    "    },\n",
    "    {\n",
    "        'id': 7,\n",
    "        'name': 'Motorbike',\n",
    "        'supercategory': 'on_road',\n",
    "    },\n",
    "    {\n",
    "        'id': 8,\n",
    "        'name': 'Bus',\n",
    "        'supercategory': 'on_road',\n",
    "    },\n",
    "    {\n",
    "        'id': 9,\n",
    "        'name': 'Svehicle',\n",
    "        'supercategory': 'on_road',\n",
    "    },\n",
    "    {\n",
    "        'id': 10,\n",
    "        'name': 'Train',\n",
    "        'supercategory': 'on_road',\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO field generation:\n",
    "def generate_image_info(image_id, file_name):\n",
    "    \"\"\"Generate information related to image.\"\"\"\n",
    "    IMAGE_SIZE = (1936,1216)\n",
    "    image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": IMAGE_SIZE[0],\n",
    "            \"height\": IMAGE_SIZE[1],\n",
    "            \"date_captured\": \"xx/xx/xx\",\n",
    "            \"license\": 0,\n",
    "            \"coco_url\": \"\",\n",
    "            \"flickr_url\": \"\"\n",
    "    }\n",
    "\n",
    "    return image_info\n",
    "\n",
    "def generate_annotation_info(image_id, bbox, category_id, tracking_id):\n",
    "    \"\"\"Generate information related to annotation.\"\"\"\n",
    "    annot_info = {\n",
    "            \"segmentation\": [],\n",
    "            \"area\": 0,\n",
    "            \"iscrowd\": 0,\n",
    "            \"image_id\": image_id,\n",
    "            \"bbox\": bbox,\n",
    "            \"category_id\": category_id,\n",
    "            \"id\": tracking_id\n",
    "    }\n",
    "    \n",
    "    return annot_info\n",
    "\n",
    "def to_coco_bbox(bbox):\n",
    "    \"\"\"Convert bbox_annot to coco format.\"\"\"\n",
    "    width = bbox[2] - bbox[0]\n",
    "    height = bbox[3] - bbox[1]\n",
    "    \n",
    "    return([bbox[0], bbox[2], width, height])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path for annotation files (or we can try to do it from the .csv):\n",
    "_path_for_data = \"../data/\"\n",
    "path_coco_annot = check_directory(_path_for_data + 'COCO_annotations/')\n",
    "train_annotations_path = os.path.join(_path_for_data, 'train_annotations')\n",
    "train_annotations_files = os.listdir(train_annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating COCO like dataset for: train_09.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_01.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_10.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_13.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_06.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_14.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_23.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_12.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_02.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_24.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_00.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_21.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_07.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_16.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_03.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_05.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_11.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_22.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_08.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_20.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_04.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_17.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_19.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_18.json...\n",
      "...Done.\n",
      "Generating COCO like dataset for: train_15.json...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "cat_dict = {'Car':1, 'Pedestrian':2,\n",
    "            'Truck':3, 'Signal':4,\n",
    "            'Signs':5, 'Bicycle':6,\n",
    "            'Motorbike':7, 'Bus':8,\n",
    "            'Svehicle':9, 'Train':10}\n",
    "\n",
    "for train_annotations_file in train_annotations_files:\n",
    "    \n",
    "    coco_output = {\n",
    "        \"info\": INFO,\n",
    "        \"licenses\": LICENSES,\n",
    "        \"categories\": CATEGORIES,\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    \n",
    "    print(\"Generating COCO like dataset for: {}...\".format(train_annotations_file))\n",
    "    content_list = []\n",
    "    with open(os.path.join(train_annotations_path, train_annotations_file)) as f:\n",
    "        video_id = train_annotations_file.split('/')[-1].split('\\\\')[-1].split('.')[0].split('_')[1]\n",
    "\n",
    "        # Load json\n",
    "        annotation = json.load(f)\n",
    "        frames = annotation[\"sequence\"]\n",
    "        frame_id = 0\n",
    "        \n",
    "        # Add COCO info for each frame: \n",
    "        for f in frames:\n",
    "            # Add image:\n",
    "            image_name = train_annotations_file.split('.')[0] + '/' + str(frame_id) + '.png'\n",
    "            image_info = generate_image_info(frame_id, image_name)\n",
    "            coco_output[\"images\"].append(image_info)\n",
    "\n",
    "            # Extract annotation information\n",
    "            for cat in cat_dict:\n",
    "                try:\n",
    "                    for detected_cat in f[cat]:\n",
    "                        coco_bbox  = to_coco_bbox(detected_cat['box2d'])\n",
    "                        annot_info = generate_annotation_info(frame_id, coco_bbox, \n",
    "                                                              cat_dict[cat], detected_cat['id'])\n",
    "                        coco_output[\"annotations\"].append(annot_info)\n",
    "                except Exception as e:\n",
    "                    #print(\"No {} in this frame (or other error type)\".format(e))\n",
    "                    pass\n",
    "\n",
    "            frame_id += 1\n",
    "            \n",
    "        # Write json file:\n",
    "        json_file_name = _path_for_data + path_coco_annot + train_annotations_file.split('.')[0] + '.json'\n",
    "        with open(json_file_name, 'w+') as output_json_file:\n",
    "            json.dump(coco_output, output_json_file)\n",
    "        \n",
    "        output_json_file.close()\n",
    "        print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "=============\n",
      "  description: AI on edge dataset\n",
      "  url: https://signate.jp/competitions/256/data\n",
      "  version: 0.1\n",
      "  year: 2020\n",
      "  contributor: MLT\n",
      "  date_created: 2020/05\n",
      "\n",
      "Licenses:\n",
      "=========\n",
      "  id: 1\n",
      "  name: Attribution-NonCommercial-ShareAlike License\n",
      "  url: http://creativecommons.org/licenses/by-nc-sa/2.0/\n",
      "\n",
      "\n",
      "Categories:\n",
      "=========\n",
      "  super_category: on_road\n",
      "    id 1: Car\n",
      "    id 3: Truck\n",
      "    id 4: Signal\n",
      "    id 5: Signs\n",
      "    id 6: Bicycle\n",
      "    id 7: Motorbike\n",
      "    id 8: Bus\n",
      "    id 9: Svehicle\n",
      "    id 10: Train\n",
      "\n",
      "  super_category: on_street\n",
      "    id 2: Pedestrian\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import coco_loader\n",
    "import numpy as np\n",
    "import IPython\n",
    "\n",
    "path_coco_json = \"../data/COCO_annotations/train_09.json\"\n",
    "path_to_image = '../data/train_images/'\n",
    "coco_dataset = coco_loader.CocoDataset(path_coco_json, path_to_image)\n",
    "coco_dataset.display_info()\n",
    "coco_dataset.display_licenses()\n",
    "coco_dataset.display_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = np.random.randint(0, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 0\n",
    "html = coco_dataset.display_image(image_index, show_polys=False, show_crowds=False)\n",
    "IPython.display.HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycoco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "path_coco_json = \"../data/COCO_annotations/train_09.json\"\n",
    "path_to_image = '../data/train_images/'\n",
    "example_coco = COCO(path_coco_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = example_coco.loadCats(example_coco.getCatIds())\n",
    "category_names = [category['name'] for category in categories]\n",
    "print('Custom COCO categories: \\n{}\\n'.format(' '.join(category_names)))\n",
    "\n",
    "category_names = set([category['supercategory'] for category in categories])\n",
    "print('Custom COCO supercategories: \\n{}'.format(' '.join(category_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_ids = example_coco.getCatIds(catNms=['Car'])\n",
    "image_ids = example_coco.getImgIds(catIds=category_ids)\n",
    "image_data = example_coco.loadImgs(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display instance annotations\n",
    "image = io.imread(path_to_image + image_data['file_name'])\n",
    "plt.imshow(image); plt.axis('off')\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "annotation_ids = example_coco.getAnnIds(imgIds=image_data['id'])\n",
    "annotations = example_coco.loadAnns(annotation_ids)\n",
    "example_coco.showAnns(annotations, draw_bbox=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation from Signate:\n",
    "```\n",
    "{\"Car\": [\n",
    "            {\"id\": 5598, \"box2d\": [1825, 577, 1935, 671]}, \n",
    "            {\"id\": 5538, \"box2d\": [1181, 486, 1762, 897]}, \n",
    "            {\"id\": 5597, \"box2d\": [1099, 579, 1196, 713]}, \n",
    "            {\"id\": 5502, \"box2d\": [812, 583, 1088, 820]}, \n",
    "            {\"id\": 5596, \"box2d\": [1047, 552, 1158, 660]}\n",
    "        ], \n",
    "        \"Pedestrian\": [\n",
    "            {\"id\": 37925, \"box2d\": [620, 556, 647, 602]},\n",
    "            {\"id\": 37923, \"box2d\": [588, 545, 611, 600]}\n",
    "        ], \n",
    "        \"Signal\": [\n",
    "            {\"id\": 181, \"box2d\": [1263, 453, 1304, 481]}\n",
    "        ]}\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation from the COCO json generated:\n",
    "```\n",
    "[{\"segmentation\": [], \"area\": 0, \"iscrowd\": 0, \"image_id\": 0, \"bbox\": [1825, 1935, 110, 94], \"category_id\": 1, \"id\": 5598}, \n",
    " {\"segmentation\": [], \"area\": 0, \"iscrowd\": 0, \"image_id\": 0, \"bbox\": [1181, 1762, 581, 411], \"category_id\": 1, \"id\": 5538}, \n",
    " {\"segmentation\": [], \"area\": 0, \"iscrowd\": 0, \"image_id\": 0, \"bbox\": [1099, 1196, 97, 134], \"category_id\": 1, \"id\": 5597}, \n",
    " {\"segmentation\": [], \"area\": 0, \"iscrowd\": 0, \"image_id\": 0, \"bbox\": [812, 1088, 276, 237], \"category_id\": 1, \"id\": 5502}, \n",
    " {\"segmentation\": [], \"area\": 0, \"iscrowd\": 0, \"image_id\": 0, \"bbox\": [1047, 1158, 111, 108], \"category_id\": 1, \"id\": 5596}, \n",
    " {\"segmentation\": [], \"area\": 0, \"iscrowd\": 0, \"image_id\": 0, \"bbox\": [620, 647, 27, 46], \"category_id\": 2, \"id\": 37925}, \n",
    " {\"segmentation\": [], \"area\": 0, \"iscrowd\": 0, \"image_id\": 0, \"bbox\": [588, 611, 23, 55], \"category_id\": 2, \"id\": 37923}, \n",
    " {\"segmentation\": [], \"area\": 0, \"iscrowd\": 0, \"image_id\": 0, \"bbox\": [1263, 1304, 41, 28], \"category_id\": 4, \"id\": 181},\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenght = len(annotation_ids)\n",
    "print(\"Number of object in this frame {}, ids: {}\".format(lenght, annotation_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

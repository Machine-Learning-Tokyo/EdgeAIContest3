{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration:\n",
    "1. Extract json content to dataframe (panda)\n",
    "2. Basic statictics analysis on the data\n",
    "3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usefull links\n",
    "- [dataset](https://signate.jp/competitions/256/data)\n",
    "- [signate tuto](https://signate.jp/competitions/142/tutorials/9)\n",
    "- [frame extraction - signate](https://signate.jp/competitions/256/discussions/tutorial-how-to-decode-the-training-videos-to-training-images)\n",
    "- [frame label to yolo format-signate](https://signate.jp/competitions/256/discussions/tutorial-how-to-convert-labels-from-multiple-jsons-to-a-single-txt-file)\n",
    "- [panda and list as cat](https://stackoverflow.com/questions/37125174/accessing-every-1st-element-of-pandas-dataframe-column-containing-lists)\n",
    "- [team google docs](https://docs.google.com/document/d/1UPNw9wHmnnpVCJI8LBmBkJG1lyKzn-Hhh1flNZ5k2Eo/edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1] Extract json to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate one file for all video\n",
    "## Get absolute path / or specify path for data\n",
    "_path_for_data = \"../data/\"\n",
    "train_annotations_path = os.path.join(_path_for_data, 'train_annotations')\n",
    "train_annotations_files = os.listdir(train_annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters (note the spelling on Svehicle)\n",
    "IMAGE_SIZE = (1936,1216)\n",
    "IMAGE_AREA = IMAGE_SIZE[0]*IMAGE_SIZE[1]\n",
    "CATEGORIES = ['Car', 'Pedestrian', 'Truck', 'Signal', 'Signs', 'Bicycle', 'Motorbike', 'Bus', 'Svehicle', 'Train']\n",
    "\n",
    "# Dataframe content:\n",
    "column_names = [\"video_id\", \"frame_id\", \"detected_cat\", \"tracking_id\", \"bbox\"]\n",
    "annot_df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract of 1 video by 1 video, because 600x25 is too heavy to process as once.\n",
    "\n",
    "Here we extract in order::\n",
    "1. The frames\n",
    "2. The frame_id\n",
    "3. The detected category\n",
    "4. Tracking index and bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frame(frame, content_list, video_id, frame_id):\n",
    "    \"\"\"Extract the content of the frame into the df dataframe.\"\"\"\n",
    "    for classe in CATEGORIES:\n",
    "        try:\n",
    "            for detected_cat in frame[classe]:\n",
    "                # Add line to df\n",
    "                content_list.append({\"video_id\":video_id, \n",
    "                                    \"frame_id\":frame_id,\n",
    "                                    \"detected_cat\":classe, \n",
    "                                    \"tracking_id\":detected_cat['id'], \n",
    "                                    \"bbox\":detected_cat['box2d']})\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from csv:\n",
    "annot_df = pd.read_csv(\"../data/annot_df_sig.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or load from file\n",
    "for train_annotations_file in train_annotations_files:\n",
    "    content_list = []\n",
    "    with open(os.path.join(train_annotations_path, train_annotations_file)) as f:\n",
    "        video_id = train_annotations_file.split('/')[-1].split('\\\\')[-1].split('.')[0].split('_')[1]\n",
    "\n",
    "        # Load json and split frame\n",
    "        annotation = json.load(f)\n",
    "        frames = annotation[\"sequence\"]\n",
    "        print(\"Extracting video train_{} a total of {} frames...\".format(video_id, len(frames)))\n",
    "\n",
    "        # Extract each frame content into dataset\n",
    "        for frame_id, frame in enumerate(frames):\n",
    "            extract_frame(frame, content_list, video_id, frame_id)\n",
    "\n",
    "        # Writting in the dataframe\n",
    "        annot_df = annot_df.append(content_list)\n",
    "        print(\"...Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3] WIP Basic exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Dataframe: {}\".format(annot_df.shape))\n",
    "print(annot_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate area and ratio features\n",
    "annot_df['area'] = (annot_df.bbox.str[2] - annot_df.bbox.str[0])*(annot_df.bbox.str[3] - annot_df.bbox.str[1])\n",
    "annot_df['ratio'] = round(annot_df['area'] / IMAGE_AREA * 100, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df.to_csv(_path_for_data + '/annot_df.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df['detected_cat'].value_counts().plot(kind='bar',x='cat',y='count', title=\"Detected on ALL VIDEO - tracking id ignored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis for 1 video\n",
    "# Find the importante features to extract and then run on all video\n",
    "selected_video = annot_df.loc[annot_df.video_id=='15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_video['detected_cat'].value_counts().plot(kind='bar',x='cat',y='count', title=\"Detected on video 15 - tracking id ignored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many object by frame / without size filtering\n",
    "max_detected = annot_df.groupby(['video_id','frame_id']).detected_cat.count().max()\n",
    "min_detected = annot_df.groupby(['video_id','frame_id']).detected_cat.count().min()\n",
    "ave_detected = annot_df.groupby(['video_id','frame_id']).detected_cat.count().mean()\n",
    "print(\"Detection by frame: average: {} | max: {} | min: {}\".format(ave_detected, max_detected, min_detected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter area size criteria 1024 square pixel:\n",
    "annot_df['Area_threshold'] = annot_df['area'].apply(lambda x: True if x >= 1024 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df['Area_threshold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for car and pedestrian\n",
    "annot_df.loc[annot_df['detected_cat'].isin(['Car', 'Pedestrian'])].Area_threshold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average ratio bbox by class\n",
    "annot_df.groupby('detected_cat').ratio.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique ID - without filtering\n",
    "unique_id = annot_df.groupby('video_id')['tracking_id'].nunique()\n",
    "print(\"List of number of distincs object for each video:\")\n",
    "print(unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count repeated tracking id\n",
    "# \"Objects with 3 or more frames in each video\"\n",
    "reapeate_more_than_3 = selected_video.groupby('tracking_id').tracking_id.count().apply(lambda x: True if x>2 else False)\n",
    "print(\"There are {} objects that are not repeated more than 3 times.\".format(reapeate_more_than_3.values.tolist().count(False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longuest repeatition\n",
    "selected_video.groupby('tracking_id').tracking_id.count().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One car is tracked in all frame of the video - maybe need to check the video\")\n",
    "selected_video.loc[selected_video['tracking_id'] == 5686].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other analysis?\n",
    "# - tracking id lenght / class\n",
    "# - ??\n",
    "# Objects with 3 or more frames in each image\n",
    "# Objects with a rectangle size of 1024 pixÂ² or more ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_grouped = selected_video.groupby(['tracking_id'])\n",
    "frame_list = tracking_grouped.aggregate(lambda x: tuple(x)).frame_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_obstruction(frame_list):\n",
    "    return not (sorted(frame_list) == list( range( min(frame_list), max(frame_list)+1 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obstructions = frame_list.apply(lambda x: check_obstruction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list[38821]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conlusion\n",
    "\n",
    "### Category repartition:\n",
    "![all_video](all_video.png) ![15](more_car15.png)\n",
    "\n",
    "- Unbalance repartition in the data is not an issue if the same repartition appear in the test set.\n",
    "See: [prior probability](https://www.investopedia.com/terms/p/prior_probability.asp)\n",
    "\n",
    "- Note than in some video the repartition car-pedestrian is inversed (ex video 15) or more equal (eg: video 02)\n",
    "\n",
    "### Frame\n",
    "\n",
    "Detection by frame average on all video: average: 20.4038 | max: 94 | min: 1.\n",
    "\n",
    "### Area size\n",
    "The area threshold of 1024 is quite important on the dataset:\n",
    "- On the full data, **True: 199178 /False:106879**\n",
    "- On Car - Pedestrian only, **True: 143552 / False: 71963**\n",
    "\n",
    "### Tracking ID\n",
    "Tracking ID in the train set seems to be a bit tricky as some object_id doesn't appear 3 times in the dataset.\n",
    "\n",
    "Note of obstruction: Obstruction does appear in the dataset. If needed I can spend more time to find information (how often in the dataset / which category / size /...)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
